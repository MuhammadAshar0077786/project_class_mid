# -*- coding: utf-8 -*-
"""project_class_mid.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1chisEnLz6LtD4X5L1AMYAXrQ4B1wS-xS
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Dec  1 23:12:21 2020

@author: julia
"""
from sklearn.model_selection import cross_val_score
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import accuracy_score
import pandas as pd
from sklearn.model_selection import GridSearchCV
from matplotlib import pyplot as plt
df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data')

cols = ["Sex",
"Length",
"Diameter",
"Height",
"Whole",
"Shucked",
"Viscera",
"Shell",
"Rings",
]

print(df.shape)
print(df.isna().sum())
df.head()

# This means first column is categorical and rest are numerical let's get a bit more information on it
df.describe()

# Now let's add columns to make data more readable
df.columns = cols # cols were obtained from .names file from dataset
df.head()

# Rest of the preprocessing is easy, steps are 1. Assign 'X' and 'y' to dataset
# 2. use label encoder to the 'y' features and then split data in test and train
X = df.iloc[:,1:]
y = df.iloc[:,0]

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=.2, stratify=y)

# Most of the work here is done, because dataset was already pruned and available the way I wanted
# now time to apply models, I will apply models and evaluate it using cross validation (one model per cell)
# I will also plot confusion matrix if possible

# the following will not work since data has been scaled as well as enocded using one hot e
# clf.predict([[input("length must be between .075 to .815, LENGTH: "),
#                   input("diameter must be between .055 to .65, DIAMETER: "),
#                   input("height must be between 0 to 1.13, HEIGHT: "),
#                   input("whole must be between .002 to 2.8, WHOLE: "),
#                   input("shucked must be between .001 to 1.4, SHUCKED: "),
#                   input("Viscera must be between .0005 to .75, Viscera: "),
#                   input("shell must be between .0015 to 1.005, SHELL: "),
#                   input("rings must be between 1 to 29, RINGS: ")]])

# sorry sir input can't be done manually by someone on my data because it has
# been scaled as well as encoded (now the 8 columns have become 20)
X_train.shape

# Perceptron is linear model so it goes first
from sklearn.linear_model import Perceptron
clf_ppn = Perceptron(tol=1e-3, random_state=0)
clf_ppn.fit(X_train, y_train)
print("Perceptron accuracy on test data =", clf_ppn.score(X_test, y_test)*100) # 50%
accuracies = cross_val_score(estimator = clf_ppn, X = X_train, y = y_train, cv = 10)
print("Perceptron cross valid mean =", accuracies.mean()*100) # 45%
print("Perceptron cross valid stdev =", accuracies.std()*100) # 6%
plot_confusion_matrix(clf_ppn, X_test, y_test)

from sklearn.neural_network import MLPClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
X, y = make_classification(n_samples=100, random_state=1)
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,
                                                    random_state=1)
clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)
clf.predict_proba(X_test[:1])

clf.predict(X_test[:5, :])

# clf.score(X_test, y_test)



clf_ppn.predict([y_user_input])

# Let's try multilevel perceptron now (I have pruned it a bit yet accuracy is disappointing)

from sklearn.neural_network import MLPClassifier
clf_mlpc = MLPClassifier(random_state=1, max_iter=1000).fit(X_train, y_train) # 56%
# clf_mlpc = MLPClassifier(hidden_layer_sizes=(150, 15), activation='relu',
#              solver='adam', alpha=0.001, batch_size='auto', learning_rate='constant',
#             learning_rate_init=0.0001, power_t=0.5, max_iter=370, shuffle=True,
#             random_state=0, tol=0.0001, verbose=False, warm_start=False,
#             momentum=0.9, nesterovs_momentum=True, early_stopping=True,
#             validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08,
#             n_iter_no_change=10, max_fun=15000)
# clf_mlpc.fit(X_train, y_train)
# clf_mlpc.score(X_test, y_test)*100
# 54% accuracy aftere pruning

print("Multilevel Perceptron accuracy on test data =", clf_mlpc.score(X_test, y_test)*100) # 52#
accuracies = cross_val_score(estimator = clf_mlpc, X = X_train, y = y_train, cv = 10) # 2.3%
print("Multilevel Perceptron cross valid mean =", accuracies.mean()*100)
print("Multilevel Perceptron cross valid stdev =", accuracies.std()*100)
plot_confusion_matrix(clf_mlpc, X_test, y_test)

# Logistic regression

from sklearn.linear_model import LogisticRegression
lgr = LogisticRegression()
lgr.fit(X_train, y_train)
lgr_pred = lgr.predict(X_test)
accuracy_score(y_test, lgr_pred)*100 # 57%

# Following lines are generating errors that is why they are commented out.
# print("Logistic Regression accuracy on test data =", lgr.score(X_test, y_test)*100)
# accuracies = cross_val_score(estimator = lgr, X = X_train, y = y_train, cv = 10)
# print("Logistic Regression cross valid mean =", accuracies.mean()*100)
# print("Logistic Regression cross valid stdev =", accuracies.std()*100)

from sklearn.svm import SVC
svr = SVC()
svr.fit(X_train, y_train)
svr_pred = svr.predict(X_test)
print(accuracy_score(y_test, svr_pred)*100) # accuracy 55%

print("Support vector with linear kernel accuracy on test data =", svr.score(X_test, y_test)*100) # accuracy 55%
accuracies = cross_val_score(estimator = svr, X = X_train, y = y_train, cv = 10) 
print("Support vector with linear kernel cross valid mean =", accuracies.mean()*100) # accuracy 53%
print("Support vector with linear kernel cross valid stdev =", accuracies.std()*100) # 2%
plot_confusion_matrix(svr, X_test, y_test)  # doctest: +SKI\

from sklearn.svm import SVC #rbf kernel
ksvr = SVC(kernel='rbf', degree=4, gamma='auto')
ksvr.fit(X_train, y_train)
ksvr_pred = ksvr.predict(X_test)
print(accuracy_score(y_test, ksvr_pred)*100)

print("Support vector with rbf with 4 degree kernel accuracy on test data =", ksvr.score(X_test, y_test)*100) # accuracy 55%
accuracies = cross_val_score(estimator = ksvr, X = X_train, y = y_train, cv = 10) 
print("Support vector with rbf with 4 degree kernel cross valid mean =", accuracies.mean()*100) # accuracy 56%
print("Support vector with rbf with 4 degree kernel cross valid stdev =", accuracies.std()*100) # 2%
plot_confusion_matrix(ksvr, X_test, y_test)

from sklearn.naive_bayes import GaussianNB
NB_classifier = GaussianNB()
NB_classifier.fit(X_train, y_train)
NB_pred = NB_classifier.predict(X_test)
print("Naive Bayes ", accuracy_score(y_test, NB_pred))

print("Naive Bayes accuracy on test data =", NB_classifier.score(X_test, y_test)*100) # accuracy 51%
accuracies = cross_val_score(estimator = NB_classifier, X = X_train, y = y_train, cv = 10) 
print("Naive Bayes cross valid mean =", accuracies.mean()*100) # accuracy 51%
print("Naive Bayes cross valid stdev =", accuracies.std()*100) # 1%
plot_confusion_matrix(NB_classifier, X_test, y_test)

from sklearn.neighbors import KNeighborsClassifier
KNN_classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
KNN_classifier.fit(X_train, y_train)
KNN_pred = KNN_classifier.predict(X_test)
# accuracy_score(y_test, KNN_pred)

print("KNN accuracy on test data =", KNN_classifier.score(X_test, y_test)*100) # accuracy 52%
accuracies = cross_val_score(estimator = KNN_classifier, X = X_train, y = y_train, cv = 10) 
print("KNN cross valid mean =", accuracies.mean()*100) # accuracy 53%
print("KNN cross valid stdev =", accuracies.std()*100) # 2%
plot_confusion_matrix(KNN_classifier, X_test, y_test)

from sklearn.ensemble import RandomForestClassifier
rForest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
rForest.fit(X_train, y_train)
forest_pred = rForest.predict(X_test)
accuracy_score(y_test, forest_pred)

print("Random Forest accuracy on test data =", rForest.score(X_test, y_test)*100) # accuracy 56%
accuracies = cross_val_score(estimator = rForest, X = X_train, y = y_train, cv = 10) 
print("Random Forest cross valid mean =", accuracies.mean()*100) # accuracy 53%
print("Random Forest cross valid stdev =", accuracies.std()*100) # 2%
plot_confusion_matrix(rForest, X_test, y_test)

"""## REPORT REGARDING ACCURACIES OF THE MODELS

#### Random Forest cross valid mean = 52.96407185628742
#### KNN cross valid mean = 53.113772455089816
#### Naive Bayes cross valid mean = 51.856287425149695
#### Support vector with rbf with 4 degree kernel cross valid mean = 53.652694610778454
#### Support vector with linear kernel cross valid mean = 53.02395209580838
#### Logistic Regression accuracy 57%
#### Multilevel Perceptron cross valid mean = 53.38323353293413
#### Perceptron cross valid mean = 45.02994011976048

Below are abandoned models (because XGBoost is not allowed and Kmeans did not give good perdiction, its accuracy is below 10% and after pruning accuracy still stays below 30%
"""

from sklearn.cluster import KMeans
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
    kmeans.fit(X_train)
    wcss.append(kmeans.inertia_)
plt.plot(range(1, 11), wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

# Worst kind of model for this dataset
kmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 42)
y_kmeans = kmeans.fit_predict(X_test)
accuracy_score(y_test, y_kmeans) #accuray is just 20%?

from xgboost import XGBClassifier
xgb_classifier = XGBClassifier()
xgb_classifier.fit(X_train, y_train)
xgb_pred = xgb_classifier.predict(X_test)
accuracy_score(y_test, xgb_pred)
plot_confusion_matrix(xgb_classifier, X_test, y_test)
accuracies = cross_val_score(estimator = xgb_classifier, X = X_train, y = y_train, cv = 10)
print("XGB linear cross valid mean =", accuracies.mean())
print("XGB linear cross valid stdev =", accuracies.std())

param_grid1 = {
    'max_depth':[5, 4, 3, 2],
    'learning_rate':[.5, .6, .8],
    'gamma':[.01, .05, .02],
    'reg_lambda':[2],
    'scale_pos_weight':[3]
}

param_grid2 = {
    'max_depth':[5],
    'learning_rate':[.5],
    'gamma':[.01],
    'reg_lambda':[2],
    'scale_pos_weight':[3]
}

optimal_params = GridSearchCV(
    estimator= XGBClassifier(subsample=.9,
                                 colsample_bytree=.5),
    param_grid = param_grid2,
    scoring = 'roc_auc',
    verbose=0,
    n_jobs=10,
    cv=10)

# optimal_params.fit(X_train, y_train,
#                    early_stopping_rounds = 10,
#                    eval_metric='auc',
#                    eval_set = [(X_test, y_test)],
#                    verbose=True)
# print(optimal_params.best_params_)

# optimal_params.fit(X_train, y_train,
#                    eval_set = [(X_test, y_test)],
#                    verbose=True)
# print(optimal_params.best_params_)

xgb_classifier = XGBClassifier(gamma=.5, learning_rate=.5, max_depth=5, reg_lambda=2, scale_pos_weight=3)
xgb_classifier.fit(X_train, y_train)
xgb_pred = xgb_classifier.predict(X_test)
accuracy_score(y_test, xgb_pred)
plot_confusion_matrix(xgb_classifier, X_test, y_test)
accuracies = cross_val_score(estimator = xgb_classifier, X = X_train, y = y_train, cv = 10)
print("XGB linear cross valid mean =", accuracies.mean())
print("XGB linear cross valid stdev =", accuracies.std())

"""some models ran after feature extraction through PCA (and LDA) however thisis not a good idea since most of the columnswere categorical data."""

# =============================================================================
# 
# from sklearn.decomposition import PCA
# pca = PCA(n_components = None)
# X_train = pca.fit_transform(X_train)
# X_test = pca.transform(X_test)
# explained_variance = pca.explained_variance_ratio_ # so there is only one important!!!
# 
# from sklearn.decomposition import PCA
# pca = PCA(n_components = 2)
# X_train = pca.fit_transform(X_train)
# X_test = pca.transform(X_test)
# explained_variance = pca.explained_variance_ratio_ #97.2% and 2% unusually high, this could be a mistake
# 
# # reverse engineering from worst to best
# from sklearn.cluster import KMeans
# wcss = []
# for i in range(1, 11):
#     kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
#     kmeans.fit(X_train)
#     wcss.append(kmeans.inertia_)
# plt.plot(range(1, 11), wcss)
# plt.title('The Elbow Method')
# plt.xlabel('Number of clusters')
# plt.ylabel('WCSS')
# plt.show()
# 
# # Worst kind of model for this dataset
# kmeans = KMeans(n_clusters = 4, init = 'k-means++', random_state = 42)
# y_kmeans = kmeans.fit_predict(X_test)
# accuracy_score(y_test, y_kmeans) #20.2% accuracy is much higher than 9% earlier
# 
# from sklearn.ensemble import RandomForestClassifier
# rForest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
# rForest.fit(X_train, y_train)
# forest_pred = rForest.predict(X_test)
# accuracy_score(y_test, forest_pred)
# plot_confusion_matrix(rForest, X_test, y_test) # accuracy score has decresed from 56%
# # to just 48% because earlier it was using all 8 dimensions for predictions
# 
# from sklearn.ensemble import RandomForestClassifier
# rForest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
# rForest.fit(X_train, y_train)
# forest_pred = rForest.predict(X_test)
# accuracy_score(y_test, forest_pred) # again same as others.
# plot_confusion_matrix(rForest, X_test, y_test)
# 
# =============================================================================
# This drastic decreaease in accuracy is attributed to PCA application, because this dataset
# has mostly categorical features, so PCA can't be applied on it, thus deterioration in
# accuracy occoured (because now we have fewer features to make prediction from)
# perhaps LDA would be better choice in this regard, let's try that.
# =============================================================================
# 
# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
# lda = LDA(n_components = None)
# X_train = lda.fit_transform(X_train, y_train)
# X_test = lda.transform(X_test)
# 
# No LDA is no help at all, here, it just "extracted" features it considered fit, and iliminated others
# since this is not reliable either.
# =============================================================================